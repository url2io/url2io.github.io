---
layout: post
title: URL2NLP 服务发布，提供文本信息智能处理服务
category: news
tags: url2nlp product mirror

---

URL2NLP 用来对文本信息进行智能处理，提供中文分词、词性标注、关键词提取等功能。

<!--more-->

## **功能列表**

![](https://i.v2ex.co/3pWGb9vz.png)

- **中文分词**：
> 分词是大多数自然语言问题中最基本的步骤，而中文在书写时，词之间并不会通过分隔符来进行分割。
> 为了满足中文自然语言处理的需要，URL2NLP提供了一套分词系统，支持中文分词、新词发现、去停用词等功能。

- **词性标注**：
> 支持对分词后的词语进行词性标注， 词性标注方法与[ICTCLAS汉语词性标注集][ictclas]兼容。 但URL2NLP的词性标注多达57种，比ICTCLAS的39种更多。 [查看词性列表][pos_list]

- **关键词提取**：
> 关键词提取引擎可以提取出文本中最有代表性的关键词，并给出对应的权重。

<!-- ## **Demo** -->

<!-- > demo地址：[点这][test]测试效果。 -->


## **API 使用文档**

> 可以查看相关文档 ([URL2NLP API doc][doc]) 来了解如何使用。


<!-- ## **示例应用** -->
<!-- > 为了让大家近一步了解这项服务，我们写了一个教学示例 **Pageless**， 它使用 **URL2Article API** 来提取网页正文，并自动将被分成多页的文章合并成一页。 -->
 <!-- > [演示地址][pageless], 代码在 [Github: url2io-app-samples][pageless_github] -->
 <!-- > -->
<!-- > ![pageless](https://i.v2ex.co/n87a5I0Ol.png) -->

<!-- ## **Feedback** -->

<!-- That's all. 希望有兴趣的童鞋可以试用一下，然后给点反馈（使用中出现的问题、会用来开发什么、意见和建议等都可以）。 欢迎留言讨论，或者url2#sina.com，或者QQ 用户群：341180183 -->

<!-- ref -->

[ictclas]: http://ictclas.nlpir.org/nlpir/html/readme.htm
[pos_list]: http://url2io.applinzi.com#url2nlp_pos_tagging
[doc]: http://url2io.applinzi.com/docs#url2nlp_services
